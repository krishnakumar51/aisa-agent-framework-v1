"""
LangGraph Workflow Graph - COMPLETE FINAL FIXED VERSION
FIXES ALL ISSUES:
- SQLite checkpointer path (typo fix: checkpoints not chheckpoints) 
- State preservation across all nodes (task_id propagation)
- Async ainvoke for async nodes
- Proper context manager handling
- All typing imports
- Emergency fallback handling
"""
from __future__ import annotations
import json
import logging
import sqlite3
from typing import List, Dict, Any, Optional
from pathlib import Path
from datetime import datetime
import os

# LangGraph imports
try:
    from langgraph.graph import StateGraph, END
    from langgraph.checkpoint.sqlite import SqliteSaver
    from langgraph.prebuilt import ToolNode as ToolExecutor
    LANGGRAPH_AVAILABLE = True
    print("âœ… LangGraph available for workflow graph")
except ImportError as e:
    LANGGRAPH_AVAILABLE = False
    print(f"âš ï¸ LangGraph not available: {str(e)}")

# Framework imports
try:
    from app.langgraph.workflow_state import AutomationWorkflowState
    from app.langgraph.agent_nodes import create_agent_nodes
    from app.database.database_manager import get_database_manager
    FRAMEWORK_AVAILABLE = True
except ImportError as e:
    FRAMEWORK_AVAILABLE = False
    print(f"âš ï¸ Framework components not available: {str(e)}")

logger = logging.getLogger(__name__)

class WorkflowGraphManager:
    """
    Production workflow graph manager - COMPLETELY FIXED VERSION
    FIXES:
    - All SQLite path issues (typo: checkpoints not chheckpoints)
    - State preservation across nodes (task_id/platform propagation)
    - Async execution with ainvoke
    - Proper checkpointer context management
    - Emergency fallback without checkpointer
    """

    def __init__(self, task_id: int):
        self.task_id = task_id
        self.graph = None
        # Proper checkpointer management
        self._checkpointer_cm = None
        self.checkpointer = None
        self.agent_nodes = None
        self.graph_available = LANGGRAPH_AVAILABLE and FRAMEWORK_AVAILABLE
        self.initialized = False
        # Preserved extras
        self._execution_history = []
        self._current_checkpoint = None
        self._last_error = None
        logger.info(f"ðŸ”— COMPLETE FIXED Workflow Graph Manager initialized for task {task_id}")

    def _build_safe_checkpoint_path(self, checkpoint_db_path: str = None) -> str:
        """Build safe, absolute SQLite path - FIXED: correct spelling 'checkpoints' not 'chheckpoints'"""
        try:
            current_file = Path(__file__).resolve()
            project_root = current_file.parents[2]
        except (IndexError, AttributeError):
            project_root = Path.cwd()

        # CRITICAL FIX: Use 'checkpoints' not 'chheckpoints'
        checkpoints_dir = project_root / "runtime" / "checkpoints"
        checkpoints_dir.mkdir(parents=True, exist_ok=True)

        if checkpoint_db_path:
            db_path = Path(checkpoint_db_path).resolve()
        else:
            db_path = checkpoints_dir / f"workflow_{self.task_id}.sqlite"

        db_path.parent.mkdir(parents=True, exist_ok=True)
        db_path_str = str(db_path)
        logger.info(f"ðŸ›¡ï¸ FIXED Safe checkpoint DB path: {db_path_str}")
        return db_path_str

    def _build_sqlite_uri(self, db_path: str) -> str:
        """Build proper SQLite URI from file path (cross-platform)"""
        posix_path = Path(db_path).resolve().as_posix()
        # Always use sqlite:/// + absolute path
        uri = f"sqlite:///{posix_path}"
        logger.info(f"ðŸ”— SQLite URI: {uri}")
        return uri

    def _wrap_node(self, node_fn):
        """
        CRITICAL FIX: Wrap nodes to preserve state across executions
        This prevents task_id/platform/instruction from being lost
        """
        async def run(state: Dict[str, Any]) -> Dict[str, Any]:
            # Execute the node
            updates = await node_fn(state)
            # Merge updates with existing state to preserve all keys
            merged = dict(state)
            if updates:
                merged.update(updates)
            logger.debug(f"ðŸ”„ State preserved: {len(merged)} keys after node execution")
            return merged
        return run

    async def initialize_graph(self, checkpoint_db_path: str = None) -> Dict[str, Any]:
        """Initialize workflow graph - COMPLETELY FIXED"""
        if not self.graph_available:
            return {
                "success": False,
                "error": "LangGraph or framework components not available",
                "langgraph_available": LANGGRAPH_AVAILABLE,
                "framework_available": FRAMEWORK_AVAILABLE
            }

        try:
            # FIXED: Build safe checkpoint path with correct spelling
            safe_db_path = self._build_safe_checkpoint_path(checkpoint_db_path)
            sqlite_uri = self._build_sqlite_uri(safe_db_path)

            # Properly enter SqliteSaver context
            try:
                self._checkpointer_cm = SqliteSaver.from_conn_string(sqlite_uri)
                self.checkpointer = self._checkpointer_cm.__enter__()
                logger.info(f"âœ… SqliteSaver context entered successfully: {type(self.checkpointer)}")
                checkpointer_status = "enabled"
            except Exception as db_error:
                logger.warning(f"âš ï¸ Checkpointer initialization failed: {str(db_error)}")
                logger.warning(f"âš ï¸ Continuing without checkpointer (workflow will still work)")
                self._checkpointer_cm = None
                self.checkpointer = None
                checkpointer_status = "disabled_fallback"

            # Create agent nodes
            self.agent_nodes = create_agent_nodes()

            # Build workflow graph with fixed state preservation
            self._build_workflow_graph()

            self.initialized = True

            return {
                "success": True,
                "task_id": self.task_id,
                "checkpoint_db": safe_db_path,
                "sqlite_uri": sqlite_uri,
                "agents_loaded": len(self.agent_nodes),
                "graph_compiled": self.graph is not None,
                "checkpointer_status": checkpointer_status,
                "checkpointer_type": str(type(self.checkpointer)) if self.checkpointer else "None",
                "initialized_at": datetime.now().isoformat(),
                "capabilities": [
                    "workflow_execution",
                    "checkpoint_management" if self.checkpointer else "memory_only",
                    "state_recovery" if self.checkpointer else "no_recovery",
                    "step_by_step_execution",
                    "error_handling",
                    "agent_coordination",
                    "state_preservation"  # NEW: Added state preservation
                ]
            }
        except Exception as e:
            logger.error(f"âŒ Workflow graph initialization failed: {str(e)}")
            if self._checkpointer_cm:
                try:
                    self._checkpointer_cm.__exit__(None, None, None)
                except Exception as cleanup_error:
                    logger.warning(f"âš ï¸ Checkpointer cleanup failed: {str(cleanup_error)}")
                self._checkpointer_cm = None
                self.checkpointer = None

            self._last_error = str(e)
            return {
                "success": False,
                "error": f"Graph initialization failed: {str(e)}",
                "error_details": {
                    "error_type": type(e).__name__,
                    "error_message": str(e),
                    "task_id": self.task_id,
                    "timestamp": datetime.now().isoformat()
                }
            }

    def _build_workflow_graph(self):
        """Build the LangGraph workflow with state preservation - COMPLETELY FIXED"""
        workflow = StateGraph(dict)

        # CRITICAL FIX: Wrap all nodes to preserve state
        workflow.add_node("agent1", self._wrap_node(self.agent_nodes["agent1"]))
        workflow.add_node("agent2", self._wrap_node(self.agent_nodes["agent2"]))
        workflow.add_node("agent3", self._wrap_node(self.agent_nodes["agent3"]))
        workflow.add_node("agent4", self._wrap_node(self.agent_nodes["agent4"]))
        workflow.add_node("supervisor", self._wrap_node(self.agent_nodes["supervisor"]))

        # Entry
        workflow.set_entry_point("agent1")

        # Routing - unchanged
        workflow.add_conditional_edges(
            "agent1",
            self._route_from_agent1,
            {"agent2": "agent2", "supervisor": "supervisor"},
        )
        workflow.add_conditional_edges(
            "agent2",
            self._route_from_agent2,
            {"agent3": "agent3", "supervisor": "supervisor"},
        )
        workflow.add_edge("agent3", "agent4")
        workflow.add_edge("agent4", END)
        workflow.add_conditional_edges(
            "supervisor",
            self._route_from_supervisor,
            {"agent2": "agent2", "agent3": "agent3", "agent4": "agent4", "end": END},
        )

        # Compile with or without checkpointer
        if self.checkpointer is not None:
            self.graph = workflow.compile(checkpointer=self.checkpointer)
            logger.info("ðŸ”— COMPLETE FIXED Workflow graph compiled with checkpointer")
        else:
            self.graph = workflow.compile()
            logger.info("ðŸ”— COMPLETE FIXED Workflow graph compiled without checkpointer (fallback mode)")

    def _route_from_agent1(self, state: Dict[str, Any]) -> str:
        agent1_status = state.get("agent1_status")
        if agent1_status == "completed":
            logger.info("ðŸ”µ Agent1 completed successfully -> routing to Agent2")
            return "agent2"
        logger.warning(f"ðŸ”µ Agent1 failed or incomplete ({agent1_status}) -> routing to Supervisor")
        return "supervisor"

    def _route_from_agent2(self, state: Dict[str, Any]) -> str:
        agent2_status = state.get("agent2_status")
        if agent2_status == "completed":
            logger.info("ðŸ”§ Agent2 completed successfully -> routing to Agent3")
            return "agent3"
        logger.warning(f"ðŸ”§ Agent2 failed or incomplete ({agent2_status}) -> routing to Supervisor")
        return "supervisor"

    def _route_from_supervisor(self, state: Dict[str, Any]) -> str:
        next_agent = state.get("supervisor_decision", {}).get("next_agent", "end")
        return next_agent if next_agent in {"agent2", "agent3", "agent4"} else "end"

    async def execute_workflow(
        self,
        initial_state: Dict[str, Any],
        thread_id: str = None
    ) -> Dict[str, Any]:
        """Execute workflow using async ainvoke - COMPLETELY FIXED"""
        if not self.initialized:
            init_result = await self.initialize_graph()
            if not init_result["success"]:
                return init_result

        execution_start_time = datetime.now()

        try:
            if not thread_id:
                thread_id = f"workflow_task_{self.task_id}_{int(datetime.now().timestamp())}"

            if self.checkpointer is not None:
                config = {
                    "configurable": {
                        "thread_id": thread_id,
                        "checkpoint_ns": f"task-{self.task_id}",
                        "checkpoint_id": f"start_{datetime.now().isoformat()}",
                    }
                }
            else:
                config = {}

            logger.info(f"ðŸš€ Starting COMPLETE FIXED workflow execution: {thread_id}")
            logger.info(f"ðŸ“Š Initial state keys: {list(initial_state.keys())}")

            execution_attempt = {
                "thread_id": thread_id,
                "start_time": execution_start_time,
                "config": config,
                "initial_state_keys": list(initial_state.keys())
            }

            # CRITICAL FIX: use ainvoke for async nodes
            try:
                final_result = await self.graph.ainvoke(initial_state, config)
                execution_steps = 1
                execution_status = "completed"
                logger.info("âœ… COMPLETE FIXED Workflow execution completed using ainvoke() with config")
                execution_attempt.update({
                    "status": "success",
                    "execution_time": (datetime.now() - execution_start_time).total_seconds(),
                    "final_state_keys": list(final_result.keys()) if isinstance(final_result, dict) else ["non_dict_result"],
                })
            except Exception as invoke_error:
                logger.error(f"âŒ ainvoke execution failed: {str(invoke_error)}")
                # Emergency fallback without checkpointer, also async
                try:
                    logger.info("ðŸ”„ Attempting emergency fallback execution without checkpointer...")
                    temp_workflow = StateGraph(dict)
                    temp_workflow.add_node("agent1", self._wrap_node(self.agent_nodes["agent1"]))
                    temp_workflow.add_node("agent2", self._wrap_node(self.agent_nodes["agent2"]))
                    temp_workflow.add_node("agent3", self._wrap_node(self.agent_nodes["agent3"]))
                    temp_workflow.add_node("agent4", self._wrap_node(self.agent_nodes["agent4"]))
                    temp_workflow.add_node("supervisor", self._wrap_node(self.agent_nodes["supervisor"]))
                    temp_workflow.set_entry_point("agent1")
                    temp_workflow.add_conditional_edges("agent1", self._route_from_agent1, {"agent2": "agent2", "supervisor": "supervisor"})
                    temp_workflow.add_conditional_edges("agent2", self._route_from_agent2, {"agent3": "agent3", "supervisor": "supervisor"})
                    temp_workflow.add_edge("agent3", "agent4")
                    temp_workflow.add_edge("agent4", END)
                    temp_workflow.add_conditional_edges("supervisor", self._route_from_supervisor, {"agent2": "agent2", "agent3": "agent3", "agent4": "agent4", "end": END})
                    temp_graph = temp_workflow.compile()
                    final_result = await temp_graph.ainvoke(initial_state)
                    execution_steps = 1
                    execution_status = "completed_fallback"
                    logger.info("âœ… COMPLETE FIXED Emergency fallback execution succeeded without checkpointer (async)")
                    execution_attempt.update({
                        "status": "fallback_success",
                        "original_error": str(invoke_error),
                        "execution_time": (datetime.now() - execution_start_time).total_seconds(),
                    })
                except Exception as fallback_error:
                    logger.error(f"âŒ Emergency fallback execution also failed: {str(fallback_error)}")
                    execution_attempt.update({
                        "status": "failed",
                        "original_error": str(invoke_error),
                        "fallback_error": str(fallback_error),
                        "execution_time": (datetime.now() - execution_start_time).total_seconds(),
                    })
                    raise invoke_error

            self._execution_history.append(execution_attempt)

            if FRAMEWORK_AVAILABLE:
                try:
                    db_manager = await get_database_manager()
                    await db_manager.log_workflow_execution(
                        self.task_id, thread_id, execution_status,
                        execution_steps, json.dumps(final_result)
                    )
                    logger.info("âœ… Workflow completion logged to database")
                except Exception as db_error:
                    logger.warning(f"Could not log workflow completion: {str(db_error)}")

            return {
                "success": True,
                "task_id": self.task_id,
                "thread_id": thread_id,
                "execution_steps": execution_steps,
                "final_state": final_result,
                "workflow_completed": True,
                "execution_status": execution_status,
                "completed_at": datetime.now().isoformat(),
                "execution_time_seconds": (datetime.now() - execution_start_time).total_seconds(),
                "config_used": config,
                "checkpointer_used": self.checkpointer is not None,
                "agent_count": len(self.agent_nodes),
                "execution_history_count": len(self._execution_history),
                "state_preservation": "enabled",  # NEW: State preservation enabled
                "capabilities_used": [
                    "workflow_orchestration",
                    "agent_coordination",
                    "state_management",
                    "error_recovery" if execution_status == "completed_fallback" else "normal_execution",
                    "database_logging" if FRAMEWORK_AVAILABLE else "no_db_logging",
                ],
            }
        except Exception as e:
            execution_time = (datetime.now() - execution_start_time).total_seconds()
            logger.error(f"âŒ Workflow execution failed after {execution_time:.2f}s: {str(e)}")
            self._execution_history.append({
                "thread_id": thread_id,
                "start_time": execution_start_time,
                "status": "failed",
                "error": str(e),
                "execution_time": execution_time,
            })
            self._last_error = str(e)
            if FRAMEWORK_AVAILABLE:
                try:
                    db_manager = await get_database_manager()
                    await db_manager.log_workflow_execution(
                        self.task_id, thread_id or "unknown", "failed",
                        0, json.dumps({"error": str(e), "execution_time": execution_time})
                    )
                except Exception:
                    pass
            return {
                "success": False,
                "task_id": self.task_id,
                "thread_id": thread_id,
                "error": str(e),
                "error_type": type(e).__name__,
                "workflow_completed": False,
                "failed_at": datetime.now().isoformat(),
                "execution_time_seconds": execution_time,
            }

    async def get_workflow_state(self, thread_id: str, checkpoint_id: str = None) -> Dict[str, Any]:
        """Get workflow state from checkpoint - FIXED"""
        if not self.initialized:
            return {"success": False, "error": "Workflow graph not initialized", "task_id": self.task_id}

        if self.checkpointer is None:
            logger.warning("âš ï¸ No checkpointer available - cannot retrieve state")
            return {
                "success": True,
                "task_id": self.task_id,
                "thread_id": thread_id,
                "checkpoint_id": checkpoint_id,
                "state": None,
                "next_nodes": [],
                "warning": "No checkpointer attached - state not persisted",
                "retrieved_at": datetime.now().isoformat(),
            }

        try:
            config = {"configurable": {"thread_id": thread_id, "checkpoint_ns": f"task-{self.task_id}"}}
            if checkpoint_id:
                config["configurable"]["checkpoint_id"] = checkpoint_id

            try:
                state = self.graph.get_state(config)
                result = {
                    "success": True,
                    "task_id": self.task_id,
                    "thread_id": thread_id,
                    "checkpoint_id": checkpoint_id,
                    "state": state.values if state else None,
                    "next_nodes": state.next if state else [],
                    "retrieved_at": datetime.now().isoformat(),
                }
                self._current_checkpoint = {"thread_id": thread_id, "checkpoint_id": checkpoint_id, "retrieved_at": datetime.now().isoformat()}
            except Exception as get_state_error:
                logger.warning(f"Could not retrieve state from checkpointer: {str(get_state_error)}")
                result = {
                    "success": True,
                    "task_id": self.task_id,
                    "thread_id": thread_id,
                    "checkpoint_id": checkpoint_id,
                    "state": None,
                    "next_nodes": [],
                    "retrieved_at": datetime.now().isoformat(),
                    "warning": f"State retrieval failed: {str(get_state_error)}",
                }
            logger.info(f"âœ… Retrieved workflow state for thread {thread_id}")
            return result
        except Exception as e:
            logger.error(f"âŒ Get workflow state failed: {str(e)}")
            return {"success": False, "task_id": self.task_id, "thread_id": thread_id, "checkpoint_id": checkpoint_id, "error": str(e), "error_type": type(e).__name__, "failed_at": datetime.now().isoformat()}

    async def resume_workflow(self, thread_id: str, checkpoint_id: str = None) -> Dict[str, Any]:
        """Resume workflow from checkpoint - FIXED with ainvoke"""
        if not self.initialized:
            init_result = await self.initialize_graph()
            if not init_result["success"]:
                return init_result

        if self.checkpointer is None:
            logger.warning("âš ï¸ No checkpointer available - cannot resume workflow")
            return {"success": True, "task_id": self.task_id, "thread_id": thread_id, "warning": "No checkpointer attached - nothing to resume", "resumed_at": datetime.now().isoformat()}

        resume_start_time = datetime.now()
        try:
            config = {"configurable": {"thread_id": thread_id, "checkpoint_ns": f"task-{self.task_id}"}}
            if checkpoint_id:
                config["configurable"]["checkpoint_id"] = checkpoint_id

            try:
                current_state = self.graph.get_state(config)
                if not current_state:
                    return {"success": False, "task_id": self.task_id, "thread_id": thread_id, "error": f"No checkpoint found for thread {thread_id}", "failed_at": datetime.now().isoformat()}
            except Exception as state_error:
                return {"success": False, "task_id": self.task_id, "thread_id": thread_id, "error": f"Could not retrieve checkpoint for thread {thread_id}: {str(state_error)}", "failed_at": datetime.now().isoformat()}

            # CRITICAL FIX: use ainvoke for resume as well
            try:
                final_result = await self.graph.ainvoke(None, config)
                execution_steps = 1
                resume_status = "resumed_success"
                logger.info("âœ… COMPLETE FIXED Workflow resume completed using ainvoke() with config")
            except Exception as resume_error:
                logger.error(f"âŒ Resume failed: {str(resume_error)}")
                final_result = {"resumed_failed": True, "error": str(resume_error)}
                execution_steps = 0
                resume_status = "resumed_failed"

            execution_time = (datetime.now() - resume_start_time).total_seconds()
            if FRAMEWORK_AVAILABLE:
                try:
                    db_manager = await get_database_manager()
                    await db_manager.log_workflow_execution(self.task_id, thread_id, f"resumed_{resume_status}", execution_steps, json.dumps(final_result))
                except Exception as db_error:
                    logger.warning(f"Could not log workflow resume: {str(db_error)}")

            return {
                "success": True,
                "task_id": self.task_id,
                "thread_id": thread_id,
                "checkpoint_id": checkpoint_id,
                "execution_steps": execution_steps,
                "final_state": final_result,
                "workflow_resumed": True,
                "resume_status": resume_status,
                "resumed_at": datetime.now().isoformat(),
                "resume_time_seconds": execution_time,
            }
        except Exception as e:
            execution_time = (datetime.now() - resume_start_time).total_seconds()
            logger.error(f"âŒ Resume workflow failed after {execution_time:.2f}s: {str(e)}")
            return {"success": False, "task_id": self.task_id, "thread_id": thread_id, "checkpoint_id": checkpoint_id, "error": str(e), "error_type": type(e).__name__, "failed_at": datetime.now().isoformat(), "resume_time_seconds": execution_time}

    def cleanup_checkpoints(self, older_than_days: int = 7) -> Dict[str, Any]:
        """Cleanup old checkpoints - FIXED path handling"""
        try:
            try:
                current_file = Path(__file__).resolve()
                project_root = current_file.parents[2]
                # FIXED: Use correct 'checkpoints' spelling
                checkpoints_dir = project_root / "runtime" / "checkpoints"
            except (IndexError, AttributeError):
                checkpoints_dir = Path("checkpoints")

            if not checkpoints_dir.exists():
                return {"success": True, "files_cleaned": 0, "message": "No checkpoints directory found", "directory_checked": str(checkpoints_dir)}

            import time
            cutoff_time = time.time() - (older_than_days * 24 * 60 * 60)
            files_cleaned = 0
            for checkpoint_file in checkpoints_dir.glob("*.sqlite"):
                try:
                    if checkpoint_file.stat().st_mtime < cutoff_time:
                        checkpoint_file.unlink()
                        files_cleaned += 1
                        logger.info(f"ðŸ§¹ Cleaned checkpoint: {checkpoint_file.name}")
                except Exception as file_error:
                    logger.warning(f"âš ï¸ Could not clean {checkpoint_file.name}: {str(file_error)}")

            return {"success": True, "files_cleaned": files_cleaned, "cutoff_days": older_than_days, "cleaned_at": datetime.now().isoformat(), "directory": str(checkpoints_dir)}
        except Exception as e:
            logger.error(f"âŒ Checkpoint cleanup failed: {str(e)}")
            return {"success": False, "error": str(e), "error_type": type(e).__name__, "failed_at": datetime.now().isoformat()}

    def get_graph_info(self) -> Dict[str, Any]:
        """Get workflow graph information"""
        return {
            "task_id": self.task_id,
            "graph_available": self.graph_available,
            "initialized": self.initialized,
            "agents_count": len(self.agent_nodes) if self.agent_nodes else 0,
            "checkpoint_enabled": self.checkpointer is not None,
            "checkpointer_type": str(type(self.checkpointer)) if self.checkpointer else "None",
            "graph_compiled": self.graph is not None,
            "state_preservation": "enabled",  # NEW
            "capabilities": [
                "workflow_execution",
                "checkpoint_management" if self.checkpointer else "memory_only",
                "state_recovery" if self.checkpointer else "no_recovery",
                "step_by_step_execution",
                "agent_coordination",
                "error_handling",
                "execution_history",
                "state_preservation",  # NEW
            ] if self.graph_available else [],
        }

    def get_execution_history(self) -> List[Dict[str, Any]]:
        """Get workflow execution history"""
        return getattr(self, "_execution_history", [])

    def clear_execution_history(self) -> Dict[str, Any]:
        """Clear workflow execution history"""
        history_count = len(getattr(self, "_execution_history", []))
        self._execution_history = []
        self._last_error = None
        return {"success": True, "cleared_count": history_count, "cleared_at": datetime.now().isoformat()}

    def close(self):
        """Properly close checkpointer context manager"""
        if self._checkpointer_cm is not None:
            try:
                self._checkpointer_cm.__exit__(None, None, None)
                logger.info("âœ… SqliteSaver context closed successfully")
            except Exception as e:
                logger.warning(f"âš ï¸ Error closing SqliteSaver context: {str(e)}")
            finally:
                self._checkpointer_cm = None
                self.checkpointer = None

    def __del__(self):
        self.close()


# Global graph manager cache
_graph_managers = {}

def get_workflow_graph_manager(task_id: int) -> WorkflowGraphManager:
    """Get workflow graph manager for task (cached)"""
    global _graph_managers
    if task_id not in _graph_managers:
        _graph_managers[task_id] = WorkflowGraphManager(task_id)
    return _graph_managers[task_id]

def cleanup_graph_managers():
    """Cleanup cached graph managers"""
    global _graph_managers
    cleaned = 0
    for manager in _graph_managers.values():
        try:
            manager.close()
            cleaned += 1
        except Exception:
            pass
    _graph_managers.clear()
    logger.info(f"ðŸ§¹ FIXED Graph managers cache cleared and all checkpointers closed: {cleaned}")
    return {"success": True, "managers_closed": cleaned, "cleaned_at": datetime.now().isoformat()}

def get_all_graph_managers() -> Dict[int, WorkflowGraphManager]:
    """Get all active graph managers"""
    global _graph_managers
    return _graph_managers.copy()

def get_graph_manager_stats() -> Dict[str, Any]:
    """Get statistics about active graph managers"""
    global _graph_managers
    active_managers = len(_graph_managers)
    initialized_managers = sum(1 for mgr in _graph_managers.values() if mgr.initialized)
    managers_with_checkpoints = sum(1 for mgr in _graph_managers.values() if mgr.checkpointer is not None)

    return {
        "active_managers": active_managers,
        "initialized_managers": initialized_managers,
        "managers_with_checkpoints": managers_with_checkpoints,
        "managers_without_checkpoints": active_managers - managers_with_checkpoints,
        "framework_status": {
            "langgraph_available": LANGGRAPH_AVAILABLE,
            "framework_available": FRAMEWORK_AVAILABLE
        },
        "stats_generated_at": datetime.now().isoformat()
    }